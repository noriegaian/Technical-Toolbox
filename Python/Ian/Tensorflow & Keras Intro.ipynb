{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, utils, backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = tf.constant('Hello World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions have Replaced Sessions (TF2 v TF1)\n",
    "\n",
    "Examples below are from: https://www.tensorflow.org/guide/function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function add at 0x0000014E7491AC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function add at 0x0000014E7491AC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "add(tf.ones([2,2]), tf.ones([2,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Functions can be faster than eager code, especially for graphs with many small ops. But for graphs with a few expensive ops (e.g., convolutions) there may not be much of a time difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function conv_fn at 0x0000014E74927048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function conv_fn at 0x0000014E74927048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Eager conv: 0.6368969000000106\n",
      "Function conv: 0.5236745000000269\n",
      "Note how there's not much difference in performance for convolutions\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "conv_layer = tf.keras.layers.Conv2D(100,3)\n",
    "\n",
    "@tf.function\n",
    "def conv_fn(image):\n",
    "    return conv_layer(image)\n",
    "\n",
    "image = tf.zeros([1, 200, 200, 100])\n",
    "#Warm up\n",
    "conv_layer(image); conv_fn(image)\n",
    "print(\"Eager conv:\", timeit.timeit(lambda: conv_layer(image), number = 10))\n",
    "print(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number = 10))\n",
    "print(\"Note how there's not much difference in performance for convolutions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Image Data Set\n",
    "\n",
    "https://www.tensorflow.org/datasets/keras_example#load_a_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install tensorflow-datasets & tfds-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found a different version 3.0.1 of dataset mnist in data_dir C:\\Users\\ianno\\tensorflow_datasets. Using currently defined version 3.0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset mnist/3.0.0 (download: 11.06 MiB, generated: Unknown size, total: 11.06 MiB) to C:\\Users\\ianno\\tensorflow_datasets\\mnist\\3.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
      "local data directory. If you'd instead prefer to read directly from our public\n",
      "GCS bucket (recommended if you're running on GCP), you can instead set\n",
      "data_dir=gs://tfds-data/datasets.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Dl Completed...', max=4, style=ProgressStyle(description_widtâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dataset mnist downloaded and prepared to C:\\Users\\ianno\\tensorflow_datasets\\mnist\\3.0.0. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist', #name of dataset\n",
    "    split = ['train','test'], #train/test split\n",
    "    shuffle_files = True, #good to shuffle training data especially when using large datasets\n",
    "    as_supervised = True, #returns a tuple instead of a dictionary\n",
    "    with_info = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function normalize_img at 0x0000014E770AA828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function normalize_img at 0x0000014E770AA828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function normalize_img at 0x0000014E770AA828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "#build training pipeline\n",
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images: 'uint8' -> 'float32'.\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "#TFDS provides images of type uint8 while model expects float32, this normalizes images\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "#as the dataset is being fit into memory, cache before shuffling for better performance\n",
    "ds_train = ds_train.cache()\n",
    "#for true randomness, set the shuffle buffer to full dataset size\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "#batch elements of the dataset after shuffling to get unique batches at each epoch\n",
    "ds_train = ds_train.batch(128)\n",
    "#good practice to end the pipeline by prefetching for performance\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build evaluation pipeline\n",
    "    #similar to training pipeline but don't need to call shuffle and caching\n",
    "    #is done after batching because batches can be the same between epochs\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and train the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)), #transforms the format of the images (28x28) to a one-dimensional array\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'), #first Dense layer that has 128 nodes/neurons; recall we can play around with activiation method (e.g., relu)\n",
    "    tf.keras.layers.Dense(10) #second Dense layer returns the desired output (i.e., 10 in this case for numbers 0-9)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000014E773381F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000014E773381F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000014E773381F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "    463/Unknown - 5s 5s/step - loss: 2.4957 - sparse_categorical_accuracy: 0.062 - 5s 4ms/step - loss: 2.1164 - sparse_categorical_accuracy: 0.27 - 5s 4ms/step - loss: 1.8940 - sparse_categorical_accuracy: 0.39 - 5s 4ms/step - loss: 1.7103 - sparse_categorical_accuracy: 0.47 - 5s 4ms/step - loss: 1.5565 - sparse_categorical_accuracy: 0.53 - 5s 4ms/step - loss: 1.4363 - sparse_categorical_accuracy: 0.57 - 5s 4ms/step - loss: 1.3399 - sparse_categorical_accuracy: 0.60 - 5s 4ms/step - loss: 1.2615 - sparse_categorical_accuracy: 0.63 - 5s 4ms/step - loss: 1.1958 - sparse_categorical_accuracy: 0.65 - 5s 4ms/step - loss: 1.1437 - sparse_categorical_accuracy: 0.67 - 5s 4ms/step - loss: 1.0946 - sparse_categorical_accuracy: 0.68 - 5s 4ms/step - loss: 1.0515 - sparse_categorical_accuracy: 0.69 - 5s 4ms/step - loss: 1.0134 - sparse_categorical_accuracy: 0.71 - 5s 4ms/step - loss: 0.9820 - sparse_categorical_accuracy: 0.72 - 5s 4ms/step - loss: 0.9514 - sparse_categorical_accuracy: 0.72 - 6s 4ms/step - loss: 0.9237 - sparse_categorical_accuracy: 0.73 - 6s 4ms/step - loss: 0.8984 - sparse_categorical_accuracy: 0.74 - 6s 4ms/step - loss: 0.8752 - sparse_categorical_accuracy: 0.75 - 6s 4ms/step - loss: 0.8555 - sparse_categorical_accuracy: 0.75 - 6s 4ms/step - loss: 0.8356 - sparse_categorical_accuracy: 0.76 - 6s 4ms/step - loss: 0.8172 - sparse_categorical_accuracy: 0.76 - 6s 4ms/step - loss: 0.7999 - sparse_categorical_accuracy: 0.77 - 6s 4ms/step - loss: 0.7839 - sparse_categorical_accuracy: 0.77 - 6s 4ms/step - loss: 0.7689 - sparse_categorical_accuracy: 0.78 - 6s 4ms/step - loss: 0.7547 - sparse_categorical_accuracy: 0.78 - 6s 4ms/step - loss: 0.7415 - sparse_categorical_accuracy: 0.79 - 6s 4ms/step - loss: 0.7299 - sparse_categorical_accuracy: 0.79 - 6s 4ms/step - loss: 0.7180 - sparse_categorical_accuracy: 0.79 - 6s 4ms/step - loss: 0.7067 - sparse_categorical_accuracy: 0.80 - 6s 4ms/step - loss: 0.6960 - sparse_categorical_accuracy: 0.80 - 6s 4ms/step - loss: 0.6850 - sparse_categorical_accuracy: 0.80 - 6s 4ms/step - loss: 0.6732 - sparse_categorical_accuracy: 0.81 - 6s 4ms/step - loss: 0.6633 - sparse_categorical_accuracy: 0.81 - 6s 4ms/step - loss: 0.6546 - sparse_categorical_accuracy: 0.81 - 6s 4ms/step - loss: 0.6456 - sparse_categorical_accuracy: 0.81 - 7s 4ms/step - loss: 0.6389 - sparse_categorical_accuracy: 0.82 - 7s 4ms/step - loss: 0.6329 - sparse_categorical_accuracy: 0.8218WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000014E76E56D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000014E76E56D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000014E76E56D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "469/469 [==============================] - 9s 9ms/step - loss: 0.6289 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.1900 - val_sparse_categorical_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - ETA: 37s - loss: 0.1400 - sparse_categorical_accuracy: 0.96 - ETA: 1s - loss: 0.1637 - sparse_categorical_accuracy: 0.9584 - ETA: 2s - loss: 0.1762 - sparse_categorical_accuracy: 0.955 - ETA: 1s - loss: 0.1869 - sparse_categorical_accuracy: 0.952 - ETA: 1s - loss: 0.1916 - sparse_categorical_accuracy: 0.951 - ETA: 1s - loss: 0.1937 - sparse_categorical_accuracy: 0.950 - ETA: 1s - loss: 0.1942 - sparse_categorical_accuracy: 0.949 - ETA: 1s - loss: 0.1941 - sparse_categorical_accuracy: 0.949 - ETA: 1s - loss: 0.1939 - sparse_categorical_accuracy: 0.949 - ETA: 1s - loss: 0.1935 - sparse_categorical_accuracy: 0.948 - ETA: 1s - loss: 0.1931 - sparse_categorical_accuracy: 0.948 - ETA: 1s - loss: 0.1927 - sparse_categorical_accuracy: 0.948 - ETA: 1s - loss: 0.1925 - sparse_categorical_accuracy: 0.948 - ETA: 1s - loss: 0.1922 - sparse_categorical_accuracy: 0.948 - ETA: 1s - loss: 0.1919 - sparse_categorical_accuracy: 0.948 - ETA: 1s - loss: 0.1916 - sparse_categorical_accuracy: 0.948 - ETA: 1s - loss: 0.1914 - sparse_categorical_accuracy: 0.948 - ETA: 1s - loss: 0.1911 - sparse_categorical_accuracy: 0.948 - ETA: 1s - loss: 0.1907 - sparse_categorical_accuracy: 0.948 - ETA: 1s - loss: 0.1903 - sparse_categorical_accuracy: 0.948 - ETA: 1s - loss: 0.1899 - sparse_categorical_accuracy: 0.948 - ETA: 0s - loss: 0.1894 - sparse_categorical_accuracy: 0.948 - ETA: 0s - loss: 0.1890 - sparse_categorical_accuracy: 0.948 - ETA: 0s - loss: 0.1885 - sparse_categorical_accuracy: 0.948 - ETA: 0s - loss: 0.1881 - sparse_categorical_accuracy: 0.948 - ETA: 0s - loss: 0.1876 - sparse_categorical_accuracy: 0.948 - ETA: 0s - loss: 0.1872 - sparse_categorical_accuracy: 0.948 - ETA: 0s - loss: 0.1867 - sparse_categorical_accuracy: 0.948 - ETA: 0s - loss: 0.1862 - sparse_categorical_accuracy: 0.948 - ETA: 0s - loss: 0.1856 - sparse_categorical_accuracy: 0.948 - ETA: 0s - loss: 0.1852 - sparse_categorical_accuracy: 0.948 - ETA: 0s - loss: 0.1848 - sparse_categorical_accuracy: 0.948 - ETA: 0s - loss: 0.1843 - sparse_categorical_accuracy: 0.948 - ETA: 0s - loss: 0.1839 - sparse_categorical_accuracy: 0.949 - ETA: 0s - loss: 0.1834 - sparse_categorical_accuracy: 0.949 - ETA: 0s - loss: 0.1829 - sparse_categorical_accuracy: 0.949 - ETA: 0s - loss: 0.1823 - sparse_categorical_accuracy: 0.949 - ETA: 0s - loss: 0.1819 - sparse_categorical_accuracy: 0.949 - ETA: 0s - loss: 0.1813 - sparse_categorical_accuracy: 0.949 - 2s 5ms/step - loss: 0.1813 - sparse_categorical_accuracy: 0.9495 - val_loss: 0.1407 - val_sparse_categorical_accuracy: 0.9597\n",
      "Epoch 3/6\n",
      "469/469 [==============================] - ETA: 34s - loss: 0.3029 - sparse_categorical_accuracy: 0.92 - ETA: 1s - loss: 0.1623 - sparse_categorical_accuracy: 0.9570 - ETA: 1s - loss: 0.1503 - sparse_categorical_accuracy: 0.959 - ETA: 1s - loss: 0.1431 - sparse_categorical_accuracy: 0.961 - ETA: 1s - loss: 0.1394 - sparse_categorical_accuracy: 0.962 - ETA: 1s - loss: 0.1371 - sparse_categorical_accuracy: 0.962 - ETA: 1s - loss: 0.1355 - sparse_categorical_accuracy: 0.963 - ETA: 1s - loss: 0.1345 - sparse_categorical_accuracy: 0.963 - ETA: 1s - loss: 0.1335 - sparse_categorical_accuracy: 0.963 - ETA: 1s - loss: 0.1328 - sparse_categorical_accuracy: 0.963 - ETA: 1s - loss: 0.1321 - sparse_categorical_accuracy: 0.963 - ETA: 1s - loss: 0.1315 - sparse_categorical_accuracy: 0.963 - ETA: 1s - loss: 0.1310 - sparse_categorical_accuracy: 0.963 - ETA: 1s - loss: 0.1306 - sparse_categorical_accuracy: 0.963 - ETA: 1s - loss: 0.1300 - sparse_categorical_accuracy: 0.963 - ETA: 1s - loss: 0.1295 - sparse_categorical_accuracy: 0.963 - ETA: 0s - loss: 0.1288 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1284 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1280 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1277 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1275 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1274 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1272 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1271 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1269 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1267 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1265 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1263 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1261 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1260 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1258 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1256 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1254 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1252 - sparse_categorical_accuracy: 0.964 - ETA: 0s - loss: 0.1250 - sparse_categorical_accuracy: 0.964 - 2s 4ms/step - loss: 0.1250 - sparse_categorical_accuracy: 0.9645 - val_loss: 0.1090 - val_sparse_categorical_accuracy: 0.9665\n",
      "Epoch 4/6\n",
      "469/469 [==============================] - ETA: 36s - loss: 0.0692 - sparse_categorical_accuracy: 0.97 - ETA: 1s - loss: 0.1015 - sparse_categorical_accuracy: 0.9730 - ETA: 1s - loss: 0.0980 - sparse_categorical_accuracy: 0.973 - ETA: 1s - loss: 0.0953 - sparse_categorical_accuracy: 0.974 - ETA: 1s - loss: 0.0939 - sparse_categorical_accuracy: 0.974 - ETA: 1s - loss: 0.0932 - sparse_categorical_accuracy: 0.974 - ETA: 1s - loss: 0.0929 - sparse_categorical_accuracy: 0.974 - ETA: 1s - loss: 0.0928 - sparse_categorical_accuracy: 0.974 - ETA: 1s - loss: 0.0927 - sparse_categorical_accuracy: 0.974 - ETA: 1s - loss: 0.0926 - sparse_categorical_accuracy: 0.974 - ETA: 1s - loss: 0.0925 - sparse_categorical_accuracy: 0.974 - ETA: 1s - loss: 0.0924 - sparse_categorical_accuracy: 0.974 - ETA: 1s - loss: 0.0923 - sparse_categorical_accuracy: 0.974 - ETA: 1s - loss: 0.0922 - sparse_categorical_accuracy: 0.974 - ETA: 1s - loss: 0.0922 - sparse_categorical_accuracy: 0.974 - ETA: 1s - loss: 0.0922 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0921 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0921 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0921 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0920 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0920 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0920 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0919 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0919 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0919 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0918 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0918 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0918 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0918 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0918 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0918 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0918 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0918 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0918 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0918 - sparse_categorical_accuracy: 0.974 - ETA: 0s - loss: 0.0918 - sparse_categorical_accuracy: 0.974 - 2s 5ms/step - loss: 0.0918 - sparse_categorical_accuracy: 0.9739 - val_loss: 0.0924 - val_sparse_categorical_accuracy: 0.9712\n",
      "Epoch 5/6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - ETA: 34s - loss: 0.0953 - sparse_categorical_accuracy: 0.96 - ETA: 1s - loss: 0.0837 - sparse_categorical_accuracy: 0.9743 - ETA: 1s - loss: 0.0793 - sparse_categorical_accuracy: 0.976 - ETA: 1s - loss: 0.0774 - sparse_categorical_accuracy: 0.977 - ETA: 1s - loss: 0.0766 - sparse_categorical_accuracy: 0.978 - ETA: 1s - loss: 0.0761 - sparse_categorical_accuracy: 0.978 - ETA: 1s - loss: 0.0761 - sparse_categorical_accuracy: 0.978 - ETA: 1s - loss: 0.0758 - sparse_categorical_accuracy: 0.978 - ETA: 1s - loss: 0.0757 - sparse_categorical_accuracy: 0.978 - ETA: 1s - loss: 0.0755 - sparse_categorical_accuracy: 0.978 - ETA: 1s - loss: 0.0754 - sparse_categorical_accuracy: 0.978 - ETA: 1s - loss: 0.0752 - sparse_categorical_accuracy: 0.978 - ETA: 1s - loss: 0.0751 - sparse_categorical_accuracy: 0.978 - ETA: 1s - loss: 0.0749 - sparse_categorical_accuracy: 0.978 - ETA: 1s - loss: 0.0747 - sparse_categorical_accuracy: 0.978 - ETA: 1s - loss: 0.0746 - sparse_categorical_accuracy: 0.978 - ETA: 1s - loss: 0.0745 - sparse_categorical_accuracy: 0.978 - ETA: 1s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0745 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0745 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0743 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.978 - 2s 5ms/step - loss: 0.0744 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.0847 - val_sparse_categorical_accuracy: 0.9743\n",
      "Epoch 6/6\n",
      "469/469 [==============================] - ETA: 34s - loss: 0.0241 - sparse_categorical_accuracy: 0.99 - ETA: 1s - loss: 0.0431 - sparse_categorical_accuracy: 0.9887 - ETA: 1s - loss: 0.0532 - sparse_categorical_accuracy: 0.985 - ETA: 1s - loss: 0.0564 - sparse_categorical_accuracy: 0.983 - ETA: 1s - loss: 0.0576 - sparse_categorical_accuracy: 0.983 - ETA: 1s - loss: 0.0583 - sparse_categorical_accuracy: 0.983 - ETA: 1s - loss: 0.0592 - sparse_categorical_accuracy: 0.982 - ETA: 1s - loss: 0.0597 - sparse_categorical_accuracy: 0.982 - ETA: 1s - loss: 0.0600 - sparse_categorical_accuracy: 0.982 - ETA: 1s - loss: 0.0602 - sparse_categorical_accuracy: 0.982 - ETA: 1s - loss: 0.0604 - sparse_categorical_accuracy: 0.982 - ETA: 1s - loss: 0.0605 - sparse_categorical_accuracy: 0.982 - ETA: 1s - loss: 0.0605 - sparse_categorical_accuracy: 0.982 - ETA: 1s - loss: 0.0606 - sparse_categorical_accuracy: 0.982 - ETA: 1s - loss: 0.0606 - sparse_categorical_accuracy: 0.982 - ETA: 0s - loss: 0.0606 - sparse_categorical_accuracy: 0.982 - ETA: 0s - loss: 0.0607 - sparse_categorical_accuracy: 0.982 - ETA: 0s - loss: 0.0608 - sparse_categorical_accuracy: 0.982 - ETA: 0s - loss: 0.0609 - sparse_categorical_accuracy: 0.982 - ETA: 0s - loss: 0.0610 - sparse_categorical_accuracy: 0.982 - ETA: 0s - loss: 0.0611 - sparse_categorical_accuracy: 0.982 - ETA: 0s - loss: 0.0612 - sparse_categorical_accuracy: 0.982 - ETA: 0s - loss: 0.0613 - sparse_categorical_accuracy: 0.982 - ETA: 0s - loss: 0.0614 - sparse_categorical_accuracy: 0.981 - ETA: 0s - loss: 0.0614 - sparse_categorical_accuracy: 0.981 - ETA: 0s - loss: 0.0615 - sparse_categorical_accuracy: 0.981 - ETA: 0s - loss: 0.0615 - sparse_categorical_accuracy: 0.981 - ETA: 0s - loss: 0.0615 - sparse_categorical_accuracy: 0.981 - ETA: 0s - loss: 0.0615 - sparse_categorical_accuracy: 0.981 - ETA: 0s - loss: 0.0615 - sparse_categorical_accuracy: 0.981 - ETA: 0s - loss: 0.0616 - sparse_categorical_accuracy: 0.981 - ETA: 0s - loss: 0.0616 - sparse_categorical_accuracy: 0.981 - ETA: 0s - loss: 0.0616 - sparse_categorical_accuracy: 0.981 - ETA: 0s - loss: 0.0616 - sparse_categorical_accuracy: 0.981 - ETA: 0s - loss: 0.0616 - sparse_categorical_accuracy: 0.981 - ETA: 0s - loss: 0.0615 - sparse_categorical_accuracy: 0.981 - 2s 5ms/step - loss: 0.0615 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0812 - val_sparse_categorical_accuracy: 0.9755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14e772d9948>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train and fit the model\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
